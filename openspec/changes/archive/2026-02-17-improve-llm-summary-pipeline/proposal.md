## Why

現在のLLM要約機能は、選択した単語の出現コンテキストを最大10件までしかLLMに渡していない。頻出する単語（キャラクター名など）の場合、序盤の出現箇所だけで10件に達してしまい、中盤〜終盤の重要な情報がLLMに届かないため、精度の高い要約を生成できない。

## What Changes

- コンテキスト収集の上限（10件）を撤廃し、全マッチを収集対象とする
- 収集したコンテキストを約4000文字ごとのチャンクに分割する
- 各チャンクからLLMを使って用語に関する事実を箇条書きで抽出する（Stage 1）
- 抽出した事実群が4000文字を超える場合、再度チャンク分割→事実抽出を再帰的に繰り返す
- 最終的に4000文字以内に収まった事実群から、用語の要約を生成する（最終Stage）
- ネタバレあり/なしの分岐は入力データのフィルタリング段階で制御する（現行と同じ方式を維持）
- 最終要約プロンプトはネタバレあり/なし共通とする

## Capabilities

### New Capabilities
- `llm-summary-pipeline`: Map-Reduce方式によるLLM要約パイプライン。コンテキストのチャンク分割、再帰的な事実抽出、最終要約生成を行う

### Modified Capabilities
- `llm-summary`: プロンプト構築の要件変更。単一プロンプト方式からパイプライン方式に変更し、コンテキスト上限10件の制約を撤廃

## Impact

- `lib/features/llm_summary/data/llm_prompt_builder.dart` — プロンプト構成の大幅変更（事実抽出用・最終要約用の2種類）
- `lib/features/llm_summary/data/llm_summary_service.dart` — パイプライン処理の導入
- `lib/features/llm_summary/data/llm_client.dart` — 複数回のLLM呼び出しに対応（インターフェース変更は不要）
- LLM APIの呼び出し回数が増加するため、処理時間とコストが増加する
